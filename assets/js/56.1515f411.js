(window.webpackJsonp=window.webpackJsonp||[]).push([[56],{353:function(t,s,a){"use strict";a.r(s);var n=a(12),r=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"信效度的应用案例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#信效度的应用案例"}},[t._v("#")]),t._v(" 信效度的应用案例")]),t._v(" "),s("MyViews"),t._v(" "),s("h2",{attrs:{id:"基于ctt理论的量表编制"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基于ctt理论的量表编制"}},[t._v("#")]),t._v(" 基于CTT理论的量表编制")]),t._v(" "),s("p",[t._v("案例下载"),s("a",{attrs:{href:"https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CDFD&dbname=CDFD9908&filename=2003094723.nh&uniplatform=NZKPT&v=fKC6As8TTdks3oYb6LVkmMMKXMcPrIR3eHPPeHTpqDwXHinBApUGdegiPrVXk8SU",target:"_blank",rel:"noopener noreferrer"}},[t._v("边玉芳 学习自我效能感量表的编制与应用"),s("OutboundLink")],1)]),t._v(" "),s("details",{staticClass:"custom-block details"},[s("summary",[t._v("文章与作者介绍")]),t._v(" "),s("p",[t._v("截止2022.4.10 文章被引量792\t下载量33780")]),t._v(" "),s("p",[t._v("边玉芳，发展与教育心理学博士、博士后。北京师范大学中国基础教育质量监测协同创新中心教授、博士生导师，北京师范大学儿童家庭教育研究中心主任，北京师范大学心理健康与教育研究所所长，北京师范大学中国基础教育质量监测协同创新中心学术委员会主任、首席专家、德育领域监测的牵头人，教育部中小学心理健康教育专家指导委员会委员。")])]),t._v(" "),s("p",[t._v("经典策略理论（Classical Test Theory，CTT）是研究者所熟悉的，其基本思想是把测验的得分（ 通常称为测验的观察分）看作真分数和误差分数的线性组合，可归结为如下简单数学模型："),s("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[s("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"10.777ex",height:"2.262ex",viewBox:"0 -750 4763.6 1000"}},[s("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[s("g",{attrs:{"data-mml-node":"math"}},[s("g",{attrs:{"data-mml-node":"mi"}},[s("path",{attrs:{"data-c":"58",d:"M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"}})]),s("g",{attrs:{"data-mml-node":"mo",transform:"translate(1105.8, 0)"}},[s("text",{attrs:{"data-variant":"normal",transform:"matrix(1 0 0 -1 0 0)","font-size":"884px","font-family":"serif"}},[t._v("＝")])]),s("g",{attrs:{"data-mml-node":"mi",transform:"translate(1983.6, 0)"}},[s("path",{attrs:{"data-c":"54",d:"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"}})]),s("g",{attrs:{"data-mml-node":"mo",transform:"translate(2965.3, 0)"}},[s("text",{attrs:{"data-variant":"normal",transform:"matrix(1 0 0 -1 0 0)","font-size":"884px","font-family":"serif"}},[t._v("＋")])]),s("g",{attrs:{"data-mml-node":"msub",transform:"translate(3843.1, 0)"}},[s("g",{attrs:{"data-mml-node":"mi"}},[s("path",{attrs:{"data-c":"65",d:"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"}})]),s("g",{attrs:{"data-mml-node":"mi",transform:"translate(466, -150) scale(0.707)"}},[s("path",{attrs:{"data-c":"78",d:"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"}})])])])])])]),t._v("，X是观测分数，T 是真分数，e 是误差分。传统信度、效度、项目分析的原理与方法均建立在这一模型之上。"),s("MyCite")],1),t._v(" "),s("blockquote",[s("p",[t._v("p39 本研究的目标是编制学习自我效能感量表，因此本部分是整个研究重点之所在。整个量表编制的思路和步骤如下:")]),t._v(" "),s("ul",[s("li",[t._v("(1)采用开放式调查和访谈对教师和学生进行相应调查;")]),t._v(" "),s("li",[t._v("(2) 对国外几个典型的学习自我效能量表进行试用;")]),t._v(" "),s("li",[t._v("(3)在以上两个预备研究的基础上结合初步的学习自我效能感量表的理论框架，形成学习自我效能感量表第一稿;")]),t._v(" "),s("li",[t._v("(4)对量表第一稿进行试测，运用探索性因素分析等方法对数据进行分析，根据测试结果调整测题，形成学习自我效能感量表第二稿;")]),t._v(" "),s("li",[t._v("(5)对学习自我效能感量表第二稿进行试测，根据结果对学习自我效能感量表的框架和测题进行调整，如此反复，直到第五稿，学习自我效能感量表的结构已基本稳定，测题得以基本确定;")]),t._v(" "),s("li",[t._v("(6)经过两次的验证性因素分析验证了学习自我效能感量表的结构;")]),t._v(" "),s("li",[t._v("(7)对基本形成的学习自我效能感量表进行各种测量学指标的分析，包括测题的平均数、标准差、通俗性水平及鉴别力分析和测验的信度和效度考察，一系列结果说明测验的性能较好。")])])]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("思考")]),t._v(" "),s("p",[t._v("(2) 对国外几个典型的学习自我效能量表进行试用;")]),t._v(" "),s("p",[t._v("这一步目的何在？\n"),s("img",{attrs:{src:t.$withBase("/IRT/1.jpg"),alt:"图片加载失败"}}),t._v(" "),s("img",{attrs:{src:t.$withBase("/IRT/2.jpg"),alt:"图片加载失败"}})])]),t._v(" "),s("p",[t._v("涉及到的方法：")]),t._v(" "),s("ul",[s("li",[t._v("探索性因素分析")]),t._v(" "),s("li",[t._v("验证性因素分析")]),t._v(" "),s("li",[t._v("效标关联效度计算")]),t._v(" "),s("li",[t._v("信度系数计算")])]),t._v(" "),s("p",[t._v("测量内部一致性信度、再测信度")]),t._v(" "),s("img",{attrs:{src:t.$withBase("/IRT/3.jpg"),alt:"图片加载失败"}}),t._v(" "),s("hr"),t._v(" "),s("img",{attrs:{src:t.$withBase("/IRT/4.jpg"),alt:"图片加载失败"}}),t._v(" "),s("h2",{attrs:{id:"基于irt理论的测试题修订"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基于irt理论的测试题修订"}},[t._v("#")]),t._v(" 基于IRT理论的测试题修订")]),t._v(" "),s("h2",{attrs:{id:"irt研究案例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#irt研究案例"}},[t._v("#")]),t._v(" IRT研究案例")]),t._v(" "),s("p",[t._v("案例下载 p31"),s("a",{attrs:{href:t.$withBase("/IRT/lipeishan.pdf")}},[t._v("📂李佩珊 大学生跨学科概念理解的调查研究")])]),t._v(" "),s("p",[t._v("CTT是建立在弱假设基础上的，项目反应理论(Item Response Theory, IRT)则建立在强假设基础上的。后者有三条基本假设：")]),t._v(" "),s("ol",[s("li",[t._v("⚠️ 潜在特质空间的单维性假设——指组成某个测验的所有项目都是测量同一潜在特质；")]),t._v(" "),s("li",[t._v("局部独立性假设——指对某个被试能力而言，项目间无相关存在；")]),t._v(" "),s("li",[t._v("项目特征曲线假设则是对被试某项目的正确反应概率与其能力之间的函数关系所作的模型。")])]),t._v(" "),s("p",[t._v("IRT有各种各样的模型，其中著名的是二级评分模型中的单参数逻辑斯蒂模型（即拉什模型）和三参数逻辑斯蒂模型，后者有项目难度、项目区分度、猜测三个参数。只要找到适合数据的模型，就可以对项目进行比较精确的分析。"),s("MyCite")],1),t._v(" "),s("blockquote",[s("p",[t._v("试测环节：")]),t._v(" "),s("ol",[s("li",[t._v("信度分析\n数据显示试题信度为0.88，大于0.8，表明试题信度较高。")]),t._v(" "),s("li",[t._v("项目拟合度分析")]),t._v(" "),s("li",[t._v("区分度分析")])])]),t._v(" "),s("blockquote",[s("p",[t._v("正式测试环节：")]),t._v(" "),s("ol",[s("li",[t._v("信度分析")]),t._v(" "),s("li",[t._v("怀特图分析")]),t._v(" "),s("li",[t._v("试题难度值和项目拟合度分析")]),t._v(" "),s("li",[t._v("区分度")]),t._v(" "),s("li",[t._v("效度")])]),t._v(" "),s("ul",[s("li",[t._v("内容效度")]),t._v(" "),s("li",[t._v("单维性")])])]),t._v(" "),s("h2",{attrs:{id:"irt操作案例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#irt操作案例"}},[t._v("#")]),t._v(" IRT操作案例")]),t._v(" "),s("div",{staticClass:"custom-block warning"},[s("p",{staticClass:"custom-block-title"},[t._v("环境安装")]),t._v(" "),s("p",[t._v("需要提前安装R语言程序，请参考"),s("a",{attrs:{href:"https://www.runoob.com/r/r-tutorial.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("R语言教程"),s("OutboundLink")],1),t._v("。")]),t._v(" "),s("p",[t._v("关于IDE，推荐使用Rstudio，因为它在作图方面表现出色。您可以在"),s("a",{attrs:{href:"https://www.rstudio.com/products/rstudio/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Rstudio官网"),s("OutboundLink")],1),t._v("下载免费版。")]),t._v(" "),s("p",[t._v("使用的扩展包为"),s("a",{attrs:{href:"http://www.edmeasurementsurveys.com/TAM/Tutorials/index.htm",target:"_blank",rel:"noopener noreferrer"}},[t._v("TAM"),s("OutboundLink")],1),t._v("、"),s("a",{attrs:{href:"https://cran.r-project.org/web/packages/ltm/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("ltm"),s("OutboundLink")],1),t._v("和"),s("a",{attrs:{href:"https://cran.r-project.org/web/packages/WrightMap/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("WrightMap"),s("OutboundLink")],1)])]),t._v(" "),s("p",[s("a",{attrs:{href:"http://www.edmeasurementsurveys.com/TAM/Tutorials/data/NumeracyD1.doc",target:"_blank",rel:"noopener noreferrer"}},[t._v("📂试卷下载"),s("OutboundLink")],1)]),t._v(" "),s("p",[s("a",{attrs:{href:"http://www.edmeasurementsurveys.com/TAM/Tutorials/data/D1_scored.csv",target:"_blank",rel:"noopener noreferrer"}},[t._v("📂数据下载"),s("OutboundLink")],1)]),t._v(" "),s("h3",{attrs:{id:"扩展包配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#扩展包配置"}},[t._v("#")]),t._v(" 扩展包配置")]),t._v(" "),s("p",[t._v("以下均为Rasch模型操作步骤")]),t._v(" "),s("p",[t._v("在桌面新建一个文件夹，新建一个.txt文件并重命名为.r。")]),t._v(" "),s("img",{attrs:{src:t.$withBase("/IRT/5.jpg"),alt:"图片加载失败"}}),t._v(" "),s("p",[t._v("添加下列代码")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 引入扩展包")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TAM"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WrightMap"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("如果未下载扩展包，可以先执行下列代码")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 注意 请在终端运行，不要放在.r文件里")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# TAM 为需要安装的包的名字，注意大小写")]),t._v("\ninstall.packages"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TAM"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"读取数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#读取数据"}},[t._v("#")]),t._v(" 读取数据")]),t._v(" "),s("p",[t._v("将数据都下载到此文件夹中。")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 将“C:/Users/Lin/Desktop/Rtest"替换为文件夹的绝对路径。')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# setwd表示设置工作目录")]),t._v("\nsetwd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"C:/Users/Lin/Desktop/Rtest"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 读取数据文件,这里D1_scored.csv为文件名")]),t._v("\ndataset1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" read.csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D1_scored.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"信度分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#信度分析"}},[t._v("#")]),t._v(" 信度分析")]),t._v(" "),s("p",[t._v("执行下列代码来计算Weighted Likelihood Estimation(WLE) Reliability")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 执行TAM包的tam函数")]),t._v("\nmod1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" tam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# View()用来窗口化显示运行结果")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 计算rasch模型的能力和WLE信度")]),t._v("\nView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tam.wle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mod1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"怀特图分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#怀特图分析"}},[t._v("#")]),t._v(" 怀特图分析")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用WrightMap包进行绘图")]),t._v("\nIRT.WrightMap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mod1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"试题难度值和项目拟合度分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#试题难度值和项目拟合度分析"}},[t._v("#")]),t._v(" 试题难度值和项目拟合度分析")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 难度xsi值")]),t._v("\nView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mod1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("xsi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 项目拟合度，outfit和infit接近1的拟合度较好 ")]),t._v("\nfit "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" tam.fit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mod1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fit"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("itemfit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"区分度分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#区分度分析"}},[t._v("#")]),t._v(" 区分度分析")]),t._v(" "),s("p",[t._v("这里通过两张图来呈现。论文里使用的图是把两条曲线画在同一张图中。")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Test Information Function")]),t._v("\nplot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"IIC"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" items "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lwd "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cex.lab "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  sub "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" paste"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Call: "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" deparse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("call"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ## The Standard Error of Measurement can be plotted by")]),t._v("\nvals "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" plot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"IIC"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" items "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" plot "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"z"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" sqrt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"info"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"l"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lwd "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  xlab "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Ability"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ylab "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Standard Error"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  main "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Standard Error of Measurement"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"效度分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#效度分析"}},[t._v("#")]),t._v(" 效度分析")]),t._v(" "),s("p",[t._v("内容效度通过德尔菲法（专家评审法）来保障")]),t._v(" "),s("p",[t._v("单维性检验使用的是主成分分析法。这里的扩展包无法实现，但可以通过SPSS的探索性因子分析代替。见"),s("RouterLink",{attrs:{to:"/lin/spssD17.html"}},[t._v("探索性因素分析")])],1),t._v(" "),s("p",[t._v("完整代码如下：")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 引入扩展包")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TAM"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WrightMap"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 将“C:/Users/Lin/Desktop/Rtest"表示文件夹的绝对路径。')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# setwd表示设置工作目录")]),t._v("\nsetwd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"C:/Users/Lin/Desktop/Rtest"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 读取数据文件,这里D1_scored.csv为文件名")]),t._v("\ndataset1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" read.csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D1_scored.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 执行TAM包的tam函数")]),t._v("\nmod1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" tam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# View()用来窗口化显示运行结果")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 计算rasch模型的能力和WLE信度")]),t._v("\nView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tam.wle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mod1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用WrightMap包进行绘图")]),t._v("\nIRT.WrightMap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mod1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 难度xsi值")]),t._v("\nView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mod1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("xsi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 项目拟合度，outfit和infit接近1的拟合度较好 ")]),t._v("\nfit "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" tam.fit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mod1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fit"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("itemfit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Test Information Function")]),t._v("\nplot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"IIC"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" items "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lwd "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cex.lab "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  sub "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" paste"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Call: "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" deparse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("call"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The Standard Error of Measurement can be plotted by")]),t._v("\nvals "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" plot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"IIC"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" items "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" plot "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"z"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" sqrt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"info"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"l"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lwd "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  xlab "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Ability"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ylab "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Standard Error"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  main "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Standard Error of Measurement"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"_2pl和3pl"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2pl和3pl"}},[t._v("#")]),t._v(" 2PL和3PL")]),t._v(" "),s("p",[t._v("以上都是使用的Rasch模型,现使用2PL和3PL模型分析之。这里仅简单执行，不做各种检验、绘图。")]),t._v(" "),s("div",{staticClass:"language-R extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 引入扩展包")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ltm"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2PL")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The two-parameter logistic model for the dataset1 data")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# with the constraint that (i) the easiness parameter")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# for the 1st item equals 1 and (ii) the discrimination")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# parameter for the 13th item equals -0.5")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 令第一个元素相对难度为1，令第十三个元素的相对区分度为-0.5")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以此为基准进行二元回归")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 二元即难度和区分度")]),t._v("\nView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ltm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),t._v(" z1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" constr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rbind"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("13")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3PL")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 三元即难度、区分度、猜测性")]),t._v("\nView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tpm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"参考资料"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),s("ol",[s("li",[t._v("俞晓琳.项目反应理论与经典测验理论之比较[J].南京师大学报(社会科学版),1998(04):79-82.")]),t._v(" "),s("li",[t._v("俞晓琳.项目反应理论与经典测验理论之比较[J].南京师大学报(社会科学版),1998(04):79-82.\n"),s("MyValine")],1)])],1)}),[],!1,null,null,null);s.default=r.exports}}]);